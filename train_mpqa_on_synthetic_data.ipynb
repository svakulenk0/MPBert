{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6994\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from predicates_dictionary import predicates\n",
    "\n",
    "# number of entities in the subgraph\n",
    "MINN = 20\n",
    "MAXN = 200\n",
    "\n",
    "N_PREDICATES = 10\n",
    "N_EDGES = 1\n",
    "\n",
    "samples = []\n",
    "# generate questions using predicate labels as seeds\n",
    "for p_id, p_label in predicates.items():\n",
    "    # prepare sample\n",
    "    adjacencies, p_labels = [], []\n",
    "    \n",
    "    q = 'who is %s?' % p_label\n",
    "    \n",
    "    # generate random subgraph\n",
    "    n = np.random.randint(MINN, MAXN+1)\n",
    "    \n",
    "    # pick a seed at random\n",
    "    seed = np.random.randint(0, n)\n",
    "    \n",
    "    # pick an answer at random which is not a seed\n",
    "    answer = seed\n",
    "    while answer == seed:\n",
    "        answer = np.random.randint(0, n)\n",
    "    \n",
    "    p_labels = random.sample(list(predicates.values()), N_PREDICATES)\n",
    "    p_labels.append(p_label)\n",
    "    p_labels = list(set(p_labels))\n",
    "    \n",
    "    # generate other adjacency matrices of the same size for other predicates\n",
    "    for i, p in enumerate(p_labels):\n",
    "        \n",
    "        # sample edges\n",
    "        edges = []\n",
    "        for _ in range(N_EDGES - 1):\n",
    "            edges.append((np.random.randint(0, n), np.random.randint(0, n)))\n",
    "        \n",
    "        if p == p_label:\n",
    "            # make sure there is an edge between the answer and the seed for the correct predicate\n",
    "            edges.append((seed, answer))\n",
    "            p_idx = i\n",
    "       \n",
    "        edges = list(set(edges))\n",
    "#         print(edges)\n",
    "        adjacencies.append(edges)\n",
    "    \n",
    "    assert len(adjacencies) == len(p_labels)\n",
    "    \n",
    "    samples.append([q, p_labels, adjacencies, seed, answer, n, p_label, p_idx])\n",
    "#     break\n",
    "    \n",
    "print(len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who is member of sports team?\n",
      "member of sports team\n",
      "0\n",
      "11\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# show sample\n",
    "q, p_labels, adjacencies, seed, answer, n_entities, p_label, p_idx = samples[27]\n",
    "print(q)\n",
    "print(p_label)\n",
    "print(len(adjacencies[0]))\n",
    "\n",
    "print(len(adjacencies))\n",
    "print(len(p_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "# pre-processing specs\n",
    "n_training_samples = 5000\n",
    "max_seq_len = 200\n",
    "model_name = 'distilbert-base-uncased'\n",
    "\n",
    "# tokenizer init\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994\n"
     ]
    }
   ],
   "source": [
    "# shuffle and split dataset intro training and validation\n",
    "random.shuffle(samples)\n",
    "train_samples = samples[:n_training_samples]\n",
    "dev_samples = samples[n_training_samples:]\n",
    "print(len(dev_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 training examples\n",
      "1994 development examples\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from utils import adj\n",
    "\n",
    "\n",
    "def prepare_dataset(samples):\n",
    "    # prepare tensors for model input\n",
    "    dataset = []\n",
    "    for sample in samples:\n",
    "        question, p_labels, adjacencies, seed_idx, answer_idx, n_entities, p_label, p_idx = sample\n",
    "\n",
    "        # create a batch of samples for each predicate label separately\n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "        for p_label in p_labels:\n",
    "            # encode a text pair of the question with a predicate label\n",
    "            encoded_dict = tokenizer.encode_plus(question, p_label,\n",
    "                                                 add_special_tokens=True,\n",
    "                                                 max_length=max_seq_len,\n",
    "                                                 pad_to_max_length=True,\n",
    "                                                 return_attention_mask=True)\n",
    "            inputs = encoded_dict['input_ids']\n",
    "            attention_mask = encoded_dict['attention_mask']\n",
    "\n",
    "            input_ids.append(inputs)\n",
    "            attention_masks.append(attention_mask)\n",
    "\n",
    "        # create a sparse adjacency matrix\n",
    "        indices, relation_mask = adj(adjacencies, n_entities, len(adjacencies))\n",
    "\n",
    "        # activate seed entity\n",
    "        entities = torch.zeros(n_entities, 1)\n",
    "        entities[[seed_idx]] = 1\n",
    "\n",
    "        dataset.append([torch.tensor(input_ids),\n",
    "                        torch.tensor(attention_masks),\n",
    "                        [indices, relation_mask, entities],\n",
    "                        torch.tensor([answer_idx])])\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_dataset = prepare_dataset(train_samples)\n",
    "dev_dataset = prepare_dataset(dev_samples)\n",
    "\n",
    "print(\"%d training examples\"%(len(train_dataset)))\n",
    "print(\"%d development examples\"%(len(dev_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model before fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MessagePassingBert(\n",
       "  (bert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       "  (mp): MPLayer()\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertConfig\n",
    "\n",
    "from MPDistilBert_model import MessagePassingBert\n",
    "\n",
    "\n",
    "# model init\n",
    "config = DistilBertConfig.from_pretrained(model_name, num_labels=1)\n",
    "model = MessagePassingBert(config)\n",
    "\n",
    "# freeze embeddings layer\n",
    "for name, param in model.bert.named_parameters():                \n",
    "    if name.startswith('embeddings'):\n",
    "        param.requires_grad = False\n",
    "        \n",
    "# # freeze only the first k-1 layers of the Transformer\n",
    "# k = 6\n",
    "# ct = 0\n",
    "# for child in model.bert.transformer.layer.children():\n",
    "#     ct += 1\n",
    "#     if ct < k:\n",
    "#         for param in child.parameters():\n",
    "#             param.requires_grad = False\n",
    "#     else:\n",
    "#         print(\"Not frozen Transformer layer\")\n",
    "\n",
    "# for name, param in model.named_parameters():                \n",
    "#     if param.requires_grad:\n",
    "#         print(name)\n",
    "\n",
    "# run model on the GPU\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev set P@1: 0.00\n"
     ]
    }
   ],
   "source": [
    "def run_inference(model, dataset, samples):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    p1s = []  # measure accuracy of the top answer: P@1\n",
    "    for i, batch in enumerate(dataset):\n",
    "        sample = samples[i]\n",
    "        question, p_labels, adjacencies, seed_idx, answer_idx, n_entities, p_label, p_idx = sample\n",
    "        \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_graphs = [tensor.to(device) for tensor in batch[2]]\n",
    "        b_labels = batch[3].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # forward pass\n",
    "            loss, logits = model(b_input_ids,\n",
    "                                 b_graphs,\n",
    "                                 attention_mask=b_input_mask,\n",
    "                                 labels=b_labels)\n",
    "#             print(logits)\n",
    "#             print(len(logits.cpu().numpy()))\n",
    "            scores = logits.cpu().numpy()\n",
    "#             print(np.sort(scores)[::-1][:5])\n",
    "            predicted_idx = np.argmax(logits.cpu().numpy()).flatten()[0]\n",
    "            true_idx = b_labels.cpu().numpy()[0]\n",
    "            assert true_idx == answer_idx\n",
    "#             print(predicted_label, true_label)\n",
    "            p1 = int(predicted_idx == true_idx)\n",
    "#             print(p1)\n",
    "            p1s.append(p1)\n",
    "    \n",
    "    return p1s\n",
    "\n",
    "dev_dataset = dev_dataset[:20]\n",
    "p1s = run_inference(model, dev_dataset, dev_samples)\n",
    "print(\"Dev set P@1: %.2f\" % np.mean(p1s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune model on training split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MessagePassingBert(\n",
       "  (bert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       "  (mp): MPLayer()\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training specs\n",
    "from transformers import get_linear_schedule_with_warmup, AdamW\n",
    "\n",
    "epochs = 2\n",
    "device = 'cuda'\n",
    "\n",
    "total_steps = len(train_dataset) * epochs\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8\n",
    "                 )\n",
    "# learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "  Average training loss: 0.13\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 0.00\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "  Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 0.00\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# reduce data size\n",
    "dev_dataset = dev_dataset[:]\n",
    "train_dataset = train_dataset[:100]\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # reset the total loss for this epoch\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # put the model into training mode\n",
    "    model.train()\n",
    "\n",
    "    # for each sample of training data input as a batch of size 1\n",
    "    for step, batch in enumerate(train_dataset):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_graphs = [tensor.to(device) for tensor in batch[2]]\n",
    "        b_labels = batch[3].to(device)\n",
    "        model.zero_grad()\n",
    "#         print([tensor.shape for tensor in batch[3]])\n",
    "        \n",
    "        # forward pass\n",
    "        loss, logits = model(b_input_ids,\n",
    "                             b_graphs,\n",
    "                             attention_mask=b_input_mask,\n",
    "                             labels=b_labels)\n",
    "        \n",
    "        del b_input_ids, b_graphs, b_input_mask, b_labels, logits\n",
    "        \n",
    "        # accumulate the training loss over all of the batches\n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "        # clean up\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # clip gradient to prevent exploding\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # clean up\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache() \n",
    "\n",
    "    # training epoch is over here\n",
    "\n",
    "    # calculate average loss over all the batches\n",
    "    avg_train_loss = total_train_loss / len(train_dataset) \n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    # put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    total_eval_loss = 0\n",
    "\n",
    "    # evaluate data for one epoch\n",
    "    for step, batch in enumerate(dev_dataset):\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_graphs = [tensor.to(device) for tensor in batch[2]]\n",
    "        b_labels = batch[3].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # forward pass\n",
    "            loss, logits = model(b_input_ids,\n",
    "                                 b_graphs,\n",
    "                                 attention_mask=b_input_mask,\n",
    "                                 labels=b_labels)\n",
    "            # accumulate validation loss\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(dev_dataset)\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model after fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev set P@1: 1.00\n"
     ]
    }
   ],
   "source": [
    "dev_dataset = dev_dataset[:20]\n",
    "p1s = run_inference(model, dev_dataset, dev_samples)\n",
    "print(\"Dev set P@1: %.2f\" % np.mean(p1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
