{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6994\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from predicates_dictionary import predicates\n",
    "\n",
    "# number of entities in the subgraph\n",
    "MINN = 20\n",
    "MAXN = 200\n",
    "\n",
    "N_PREDICATES = 10\n",
    "N_EDGES = 1\n",
    "\n",
    "# prepare entity labels for each hop up to MAXN\n",
    "entity_labels_1, entity_labels_2 = [], []\n",
    "for i in range(MAXN):\n",
    "    entity_labels_1.append('Entity1%d'%i)\n",
    "    entity_labels_2.append('Entity2%d'%i)\n",
    "\n",
    "# consider all possible predicates\n",
    "p_labels = list(predicates.values())\n",
    "\n",
    "samples = []\n",
    "# generate questions for each predicate\n",
    "for p_idx, p_label in enumerate(p_labels):\n",
    "    # generate random seed subgraph with n entities\n",
    "    n = np.random.randint(MINN, MAXN+1)\n",
    "    # sample n entities for this subgraph\n",
    "    e_labels_1 = random.sample(entity_labels_1, n)\n",
    "    # pick a seed at random\n",
    "    seed_idx = np.random.randint(0, n)\n",
    "    seed_label = e_labels_1[seed_idx]\n",
    "    \n",
    "    # (1) ask first question about this predicate\n",
    "    q1 = 'what is %s of %s?' % (p_label, seed_label)\n",
    "    # sample random answer to the first question from the seed subgraph\n",
    "    a1_idx = seed_idx\n",
    "    while a1_idx == seed_idx:\n",
    "        a1_idx = np.random.randint(0, n)\n",
    "    a1 = e_labels_1[a1_idx]\n",
    "        \n",
    "    # (2) sample random entity from the seed subgraph to ask a question about\n",
    "    e_idx = seed_idx\n",
    "    while e_idx == seed_idx:\n",
    "        e_idx = np.random.randint(0, n)\n",
    "    e_label = e_labels_1[e_idx]\n",
    "    # ask next question about this entity\n",
    "    q2 = 'what about %s?' % e_label\n",
    "    # pick an answer at random in the other subgraph\n",
    "    a2_idx = np.random.randint(0, MAXN)\n",
    "    \n",
    "    # append conversation history to question\n",
    "    q = [q2, q1, a1]\n",
    "   \n",
    "    # each sample contains: question with history, predicate and entity list, and answer\n",
    "    samples.append([q, e_labels_1, e_idx, p_labels, p_idx, seed_idx, a2_idx])\n",
    "#     break\n",
    "    \n",
    "print(len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what about Entity1157?', 'what is place of birth of Entity121?', 'Entity115']\n",
      "place of birth\n",
      "6994\n"
     ]
    }
   ],
   "source": [
    "# show sample\n",
    "q, e_labels_1, e_idx, p_labels, p_idx, seed_idx, a2_idx = samples[7]\n",
    "print(q)\n",
    "print(p_labels[p_idx])\n",
    "print(len(p_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "# pre-processing specs\n",
    "n_training_samples = 5000\n",
    "max_seq_len = 200\n",
    "model_name = 'distilbert-base-uncased'\n",
    "\n",
    "# tokenizer init\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994\n"
     ]
    }
   ],
   "source": [
    "# shuffle and split dataset intro training and validation\n",
    "random.shuffle(samples)\n",
    "train_samples = samples[:n_training_samples]\n",
    "dev_samples = samples[n_training_samples:]\n",
    "print(len(dev_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 training examples\n",
      "2 development examples\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def prepare_dataset(samples, limit=2):\n",
    "    # prepare tensors for model input\n",
    "    dataset = []\n",
    "    for sample in samples[:limit]:\n",
    "        question, e_labels_1, e_idx, p_labels, p_idx, seed_idx, a2_idx = sample\n",
    "\n",
    "        # encode predicates\n",
    "        p_batch = tokenizer([question]*len(p_labels), p_labels, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        # encode entities\n",
    "        e_batch = tokenizer([question]*len(e_labels_1), e_labels_1, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "      \n",
    "        dataset.append([p_batch,\n",
    "                        e_batch,\n",
    "                        torch.tensor([a2_idx])])\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_dataset = prepare_dataset(train_samples)\n",
    "dev_dataset = prepare_dataset(dev_samples)\n",
    "\n",
    "print(\"%d training examples\"%(len(train_dataset)))\n",
    "print(\"%d development examples\"%(len(dev_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model before fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MessagePassingBert(\n",
       "  (bert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.9, inplace=False)\n",
       "  (subgraph_sampling): SamplingLayer()\n",
       "  (mp): MPLayer()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertConfig\n",
    "\n",
    "from MPDistilBert_sampler_model import MessagePassingBert\n",
    "\n",
    "\n",
    "# model init\n",
    "config = DistilBertConfig.from_pretrained(model_name, num_labels=1)\n",
    "model = MessagePassingBert(config)\n",
    "\n",
    "# freeze embeddings layer\n",
    "for name, param in model.bert.named_parameters():                \n",
    "    if name.startswith('embeddings'):\n",
    "        param.requires_grad = False\n",
    "\n",
    "# run model on the GPU \"cuda\"\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7277ffb26bcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mdev_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdev_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mp1s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dev set P@1: %.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-7277ffb26bcc>\u001b[0m in \u001b[0;36mrun_inference\u001b[0;34m(model, dataset, samples)\u001b[0m\n\u001b[1;32m     14\u001b[0m             loss, logits = model(p_input_ids,\n\u001b[1;32m     15\u001b[0m                                  \u001b[0me_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                                  labels=a_labels)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m#             print(logits)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#             print(len(logits.cpu().numpy()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/transformers/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'labels'"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "def run_inference(model, dataset, samples):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    p1s = []  # measure accuracy of the top answer: P@1\n",
    "    for i, batch in enumerate(dataset):\n",
    "        p_input_ids = batch[0].to(device)\n",
    "        e_input_ids = batch[1].to(device)\n",
    "        a_labels = batch[2].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # forward pass\n",
    "            loss, logits = model(p_input_ids,\n",
    "                                 e_input_ids,\n",
    "                                 labels=a_labels)\n",
    "#             print(logits)\n",
    "#             print(len(logits.cpu().numpy()))\n",
    "            scores = logits.cpu().numpy()\n",
    "#             print(np.sort(scores)[::-1][:5])\n",
    "            predicted_idx = np.argmax(logits.cpu().numpy()).flatten()[0]\n",
    "            true_idx = b_labels.cpu().numpy()[0]\n",
    "            \n",
    "#             print(predicted_label, true_label)\n",
    "            p1 = int(predicted_idx == true_idx)\n",
    "#             print(p1)\n",
    "            p1s.append(p1)\n",
    "    \n",
    "    return p1s\n",
    "\n",
    "dev_dataset = dev_dataset[:20]\n",
    "p1s = run_inference(model, dev_dataset, dev_samples)\n",
    "print(\"Dev set P@1: %.2f\" % np.mean(p1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
